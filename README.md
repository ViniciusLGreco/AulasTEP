# AulasTEP
Reposit√≥rio com todas as aulas de T√≥picos Especiais em Programa√ß√£o.

# Aula 1 - dia 08/08/2024
N√£o teve aula

# Aula 2
Dia 15/08/2024

Criar conta no GPT
Passo a passo:

Acesse o site da OpenAI: V√° at√© a p√°gina principal da OpenAI: https://platform.openai.com/
Clique em "Sign Up" (Inscreva-se): Geralmente, este bot√£o se encontra no canto superior direito da p√°gina.
Preencha as informa√ß√µes solicitadas:
E-mail: Insira um endere√ßo de e-mail v√°lido.
Senha: Crie uma senha forte e segura.
Outras informa√ß√µes: Podem ser solicitados outros dados, como nome completo e organiza√ß√£o (se aplic√°vel).
Verifique seu e-mail: A OpenAI enviar√° um e-mail de verifica√ß√£o para confirmar sua identidade. Clique no link de verifica√ß√£o dentro do e-mail.
Complete o perfil (opcional): Ap√≥s a verifica√ß√£o, voc√™ pode personalizar seu perfil adicionando informa√ß√µes adicionais, como sua √°rea de interesse e como planeja usar as ferramentas da OpenAI.
Comece a usar: Com a conta criada, voc√™ ter√° acesso aos diferentes produtos e servi√ßos oferecidos pela OpenAI, como o ChatGPT, API da OpenAI e outros.
Criar conta no Groq
https://groq.com/

Trabalhando com ambientes Virtuais no Python
Ambientes virtuais s√£o como "ilhas" isoladas dentro do seu sistema, onde voc√™ pode instalar e gerenciar pacotes Python de forma independente para cada projeto. Isso significa que cada projeto ter√° sua pr√≥pria vers√£o do Python e suas pr√≥prias bibliotecas, evitando conflitos entre diferentes vers√µes e depend√™ncias.

Por que usar ambientes virtuais?

Isolamento de projetos: Cada projeto ter√° seu pr√≥prio conjunto de pacotes, evitando conflitos de vers√£o.
Gerenciamento de depend√™ncias: Facilita o controle das vers√µes exatas de cada pacote utilizado em um projeto.
Reprodutibilidade: Permite que outros desenvolvedores reproduzam o ambiente do seu projeto com facilidade.
Organiza√ß√£o: Mant√©m seu ambiente Python organizado e livre de confus√µes.
a) Criando um ambiente virtual local com Python no terminal

python -m venv meu_ambiente # Ativar ambiente - Linux;WSL source meu_ambiente/bin/activate # Ativar ambiente - windows meu_ambiente\Scripts\activate # Instalando pacotes pip install <module name> # Dica. Nomear ambiente como .venv
b) Criando um ambiente virtual local com Python no VSCODE

Testes pr√°ticos:
Search Tools GPTs

.Chat com GPT
.Imagem com DALLE-3
.Texto para audio Groq
.Audio para texto
.Chat com Groq

PDF de LLMs(https://github.com/ViniciusLGreco/AulasTEP/blob/main/LLMs.pdf)

# Aula 3
 Modelos LLM, Hugging Face e Ollama

Finalizar Exemplo Docker
Baixar Ferramentas

- Baixar LLM Studio
- Baixar Anything LLM
- Baixar Ollama

Baixar Modelos e salvar na pasta

```d
C:\Users\<SEU_USUARIO>\.cache\lm-studio\models
```

Conhecer os detalhes dos modelos.

# Aula 4


**O que √© Engenharia de Prompt**

A Engenharia de Prompts √© uma disciplina emergente que se dedica a criar e otimizar instru√ß√µes textuais, ou "prompts", que direcionam o comportamento dos LLMs para produzir respostas precisas e √∫teis. Este campo √© essencial para maximizar a efici√™ncia e a precis√£o dos modelos de linguagem, pois determina como esses modelos interpretam e respondem √†s solicita√ß√µes dos usu√°rios.
---

- Formula√ß√£o de entradas que orientam o comportamento dos modelos de linguagem.

- A cria√ß√£o de prompts eficazes √© um processo interativo que inclui planejamento, testes e refinamentos cont√≠nuos.

- A EP deve prezar pela clareza, neutralidade e imparcialidade.
  
  - Escolha cuidadosa das palavras para evitar interpreta√ß√µes tendenciosas

- EP inclui a cria√ß√£o e reestrutura√ß√£o de prompts existentes

- Personaliza√ß√£o de prompts para diferentes p√∫blicos e aplica√ß√µes

T√©cnicas B√°sicas de Engenharia de Prompt

---

Configura√ß√µes da LLM

- Temperatura - quanto menor a¬†`temperatura`, mais determin√≠sticos s√£o os resultados
- Tokens - cerca de 4 caracteres (english)
- TopP - Se voc√™ est√° procurando respostas exatas e factuais, mantenha isso baixo

---

Prompts B√°sicos

```d
O c√©u √©
```

Melhorando o contexto:

```d
Complete a senten√ßa:
O c√©u √©
```

---

Isto √© melhor? Bem, dissemos ao modelo para completar a frase para que o resultado fique muito melhor, pois segue exatamente o que dissemos para fazer ("complete a frase"). Essa abordagem de projetar prompts ideais para instruir o modelo a executar uma tarefa √© chamada de **engenharia de prompt**.

O Exemplo de prompt acima corresponde apenas a uma pergunta direta, em que voc√™ est√° solicitando diretamente ao modelo uma resposta sem nenhum exemplo ou demonstra√ß√£o sobre a tarefa que deseja realizar. Este modelo √© conhecido como **Zero-shot Prompting**.
---

Outra t√©cnica popular √© a *Few-shot Prompting* onde fornecemos exemplos (ou seja, demonstra√ß√µes). Os prompts de poucos tiros podem ser formatados da seguinte maneira:

```d
<Pergunta>?
<Resposta>
<Pergunta>?
<Resposta>
<Pergunta>?
<Resposta>
<Pergunta>?
```

---

Lembre-se de que n√£o √© necess√°rio usar o formato QA. O formato do prompt depende da tarefa em m√£os. 

Exemplo:

- Voc√™ pode executar uma tarefa de classifica√ß√£o simples e fornecer exemplares que demonstrem a tarefa da seguinte forma:

Prompt:

```d
Isso √© incr√≠vel! // Positivo
Isto √© mau! // Negativo
Uau, esse filme foi radical! // Positivo
Que espet√°culo horr√≠vel! //
```

---

 Elementos de um prompt

Um prompt pode conter qualquer um dos seguintes componentes:

- Instru√ß√£o - o que voc√™ deseja que o modelo execute
- Contexto - informa√ß√µes externas ou contexto adicional 
- Dados de entrada - √© a entrada ou pergunta para a qual queremos uma resposta
- Indicador de sa√≠da - indica o tipo ou formato da sa√≠da.

Nem todos os componentes s√£o necess√°rios para um prompt e o formato depende da tarefa em quest√£o. 

---

 Dicas gerais para projetar prompts

Comece Simples

> A especificidade, a simplicidade e a concis√£o geralmente lhe dar√£o melhores resultados
> Forne√ßa uma instru√ß√£o
> Experimente instru√ß√µes diferentes com palavras-chave, contextos e dados diferentes e veja o que funciona melhor para seu caso

Recomendam que as instru√ß√µes sejam colocadas no in√≠cio do prompt.

Prompt:

```d
# Instru√ß√£o #
Traduza o texto abaixo para o espanhol:
Texto: "ol√°!"
```

---

Especificidade

> Seja muito espec√≠fico sobre a instru√ß√£o e a tarefa que deseja que o modelo execute. Quanto mais descritivo e detalhado for o prompt, melhores ser√£o os resultados.

Prompt:

```d
Extraia o nome dos lugares no texto a seguir.
Formato desejado:
Local: <lista_de_nomes_de_empresa_separados_por_v√≠rgula>
Input: "Embora estes desenvolvimentos sejam encorajadores para os investigadores, muito ainda √© um mist√©rio. ‚ÄúMuitas vezes temos uma caixa preta entre o c√©rebro e o efeito que vemos na periferia‚Äù, diz Henrique Veiga-Fernandes, neuroimunologista do Centro Champalimaud para o Desconhecido em Lisboa. ‚ÄúSe queremos utiliz√°-lo no contexto terap√™utico, precisamos de facto de perceber o mecanismo."
```

---

Agora utilizando outro formato de sa√≠da (JSON).

Prompt:

```d
Extraia o nome dos lugares no texto a seguir.
Formato desejado:
Local: {"local": "{{nome_do_local}}"}
Input: "Embora estes desenvolvimentos sejam encorajadores para os investigadores, muito ainda √© um mist√©rio. ‚ÄúMuitas vezes temos uma caixa preta entre o c√©rebro e o efeito que vemos na periferia‚Äù, diz Henrique Veiga-Fernandes, neuroimunologista do Centro Champalimaud para o Desconhecido em Lisboa. ‚ÄúSe queremos utiliz√°-lo no contexto terap√™utico, precisamos de facto de perceber o mecanismo."
```

---

Evite Imprecis√µes

> Dadas as dicas acima sobre como ser detalhado e melhorar o formato, √© f√°cil cair na armadilha de querer ser muito inteligente sobre os prompts e potencialmente criar descri√ß√µes imprecisas.

Por exemplo, voc√™ pode estar interessado em aprender o conceito de engenharia de prompt. Voc√™ pode tentar algo como:

Prompt:

```d
Explique o conceito de engenharia de prompt. Mantenha a explica√ß√£o curta, apenas algumas frases, e n√£o seja muito descritivo.
```

---

N√£o est√° claro no prompt acima quantas frases usar e qual estilo. Voc√™ ainda pode obter uma boa resposta com o prompt acima, mas o melhor prompt seria aquele que √© muito espec√≠fico, conciso e direto ao ponto. Algo como:

Prompt:

```d
Use 2 a 3 frases para explicar o conceito de engenharia de prompt a um aluno do ensino m√©dio.
```

---

Fazer ou n√£o fazer?

> Outra dica comum ao criar prompts √© evitar dizer o que n√£o fazer, mas dizer o que fazer. Isso incentiva mais especificidade e concentra-se nos detalhes que levam a boas respostas do modelo.
> Aqui est√° um exemplo de um chatbot de recomenda√ß√£o de filme falhando exatamente no que eu n√£o quero que ele fa√ßa por causa de como escrevi a instru√ß√£o -- focando no que n√£o fazer.

Prompt:

```d
O agente a seguir recomenda filmes para um cliente. N√ÉO PE√áA INTERESSES. N√ÉO PE√áA INFORMA√á√ïES PESSOAIS.
Cliente: Por favor, recomende um filme baseado nos meus interesses.
Agente:
```

---

Aqui est√° um prompt melhor:

Prompt:

```d
O agente a seguir recomenda filmes para um cliente. O agente √© respons√°vel por recomendar um filme dos principais filmes de tend√™ncias globais. Deve abster-se de perguntar aos usu√°rios sobre suas prefer√™ncias e evitar pedir informa√ß√µes pessoais. Se o agente n√£o tiver um filme para recomendar, ele deve responder "Desculpe, n√£o foi poss√≠vel encontrar um filme para recomendar hoje.".
Cliente: Por favor, recomende um filme baseado nos meus interesses.
Agente:
```

---

 Exemplos de Prompts

 Resumo de texto

Uma das tarefas padr√£o na gera√ß√£o de linguagem natural √© o resumo de texto.

Digamos que estou interessado em aprender sobre antibi√≥ticos, poderia tentar um prompt como este:

---

Prompt:

```d
Explique os antibi√≥ticos
A:
```

O "A:" √© um formato de prompt expl√≠cito usado para responder perguntas. Neste exemplo, n√£o est√° claro como isso √© √∫til ou n√£o, mas deixaremos isso para exemplos posteriores.

---

Vamos apenas supor que a resposta obtida ainda √© muita informa√ß√£o e queremos resumi-la ainda mais. Na verdade, podemos instruir o modelo a resumir em uma frase da seguinte forma:

Prompt

```d
A: <resposta anterior>
Q: **Explique em uma frase.**
A:
```

---

 Extra√ß√£o de Informa√ß√µes

Embora os modelos de linguagem sejam treinados para executar a gera√ß√£o de linguagem natural e tarefas relacionadas, eles tamb√©m s√£o muito capazes de realizar classifica√ß√£o e uma s√©rie de outras tarefas de processamento de linguagem natural (NLP).

> Veja o exemplo feito anteriormente.

Esse √© um recurso poderoso que os desenvolvedores de produtos de IA j√° est√£o usando para criar produtos e experi√™ncias poderosos.

---

 Resposta a perguntas

Uma das melhores maneiras de fazer com que o modelo responda de forma espec√≠ficas √© melhorar o formato do prompt. Conforme abordado anteriormente, um prompt pode combinar instru√ß√µes, contexto, entrada e indicadores de sa√≠da para obter melhores resultados.

---

Prompt:

```
Responda a pergunta com base no contexto abaixo. Mantenha a resposta curta e concisa. Responda "N√£o tenho certeza sobre a resposta" se n√£o tiver certeza da resposta.
Contexto: Teplizumab tem suas ra√≠zes em uma empresa farmac√™utica de Nova Jersey chamada Ortho Pharmaceutical. L√°, os cientistas geraram uma vers√£o inicial do anticorpo, apelidada de OKT3. Originalmente proveniente de camundongos, a mol√©cula foi capaz de se ligar √† superf√≠cie das c√©lulas T e limitar seu potencial de morte celular. Em 1986, foi aprovado para ajudar a prevenir a rejei√ß√£o de √≥rg√£os ap√≥s transplantes renais, tornando-se o primeiro anticorpo terap√™utico permitido para uso humano.
Pergunta: De onde veio originalmente o OKT3?
Responder:
```

---

 Classifica√ß√£o de texto

At√© agora, usamos instru√ß√µes simples para executar uma tarefa. Como um engenheiro de prompt, voc√™ precisar√° melhorar o fornecimento de melhores instru√ß√µes. 

---

Vamos tentar demonstrar isso fornecendo um exemplo de classifica√ß√£o de texto.

Prompt:

```json
Classifique o texto em neutro, negativo ou positivo.
Texto: Acho que a comida estava mais ou menos.
Sentimento:
```

---

Independente da resposta, digamos que o que realmente precisamos √© que o modelo d√™ o r√≥tulo no formato exato que queremos. Como alcan√ßamos isso? 

> Existem diferentes maneiras de fazer isso. N√≥s nos preocupamos com a especificidade aqui, portanto, quanto mais informa√ß√µes pudermos fornecer, melhores ser√£o os resultados. Podemos tentar fornecer exemplos para especificar o comportamento correto. 

Vamos tentar de novo:

---

Prompt:

```json
Classifique o texto em neutro, negativo ou positivo.
Texto: Acho que as f√©rias est√£o mais ou menos.
Sentimento: positivo
Texto: Acho que a comida estava mais ou menos.
Sentimento:
```

O modelo utilizado correspondeu com suas expectativas? Qual √© o problema aqui? Procure utilizar mais exemplos. Fa√ßa um refinamento.

---

 Conversa√ß√£o (Chat)

Talvez uma das coisas mais interessantes que voc√™ pode conseguir com a engenharia imediata seja instruir o sistema LLM sobre como se comportar, sua inten√ß√£o e sua identidade. 

---

Exemplo: vamos criar um sistema de conversa√ß√£o capaz de gerar respostas mais t√©cnicas e cient√≠ficas √†s perguntas. 

Prompt:

```json
A seguir, uma conversa com um assistente de pesquisa de IA. O tom assistente √© t√©cnico e cient√≠fico.
Humano: Ol√°, quem √© voc√™?
AI: Sauda√ß√µes! Eu sou um assistente de pesquisa de IA. Como posso te ajudar hoje?
Humano: Voc√™ pode me falar sobre a cria√ß√£o de buracos negros?
AI:
```

---

Nosso assistente de pesquisa de IA parece um pouco t√©cnico demais, certo? Ok, vamos mudar esse comportamento e instruir o sistema a dar respostas mais acess√≠veis.

Prompt:

```json
A seguir, uma conversa com um assistente de pesquisa de IA. As respostas do assistente devem ser f√°ceis de entender, utilizando um vocabul√°rio acess√≠vel por alunos do ensino fundamental.
Humano: Ol√°, quem √© voc√™?
AI: Sauda√ß√µes! Eu sou um assistente de pesquisa de IA. Como posso te ajudar hoje?
Humano: Voc√™ pode me falar sobre a cria√ß√£o de buracos negros?
AI:
```

---

Voc√™ pode continuar melhorando. Tenho certeza que se voc√™ adicionar mais exemplos voc√™ pode obter resultados ainda melhores.

---

 Gera√ß√£o de C√≥digo

Uma aplica√ß√£o em que os LLMs s√£o bastante eficazes √© a gera√ß√£o de c√≥digo. O Copilot √© um √≥timo exemplo disso.

Em alguns modelos nem √© preciso descrever como a IA deve se comportar. Apenas insira o prompt e ele lhe retornar√° com uma resposta em uma determinada linguagem de programa√ß√£o.

---

Contudo, aqui vamos fornecer um prompt para o sistema:
System:

```json
Voc√™ √© um programador experiente. Ajude os usu√°rios a criarem c√≥digo que sejam simples e eficientes. Se o usu√°rio n√£o especificar a linguagem de programa√ß√£o, sempre utilize javascript como base.
```

Prompt:

```json
/*
Pergunte ao usu√°rio o nome dele e diga "Ol√°"
*/
```

Voc√™ pode ver que nem precisamos especificar a linguagem a ser usada.

---

Aprimorando o prompt conseguimos resultados muito poderosos.

```json
Tabela departamentos, colunas = [DepartmentId, DepartmentName]
Alunos da tabela, colunas = [DepartmentId, StudentId, StudentName]
Crie uma consulta MySQL para todos os alunos do Departamento de Ci√™ncia da Computa√ß√£o
```

---

 Racioc√≠nio

os LLMs atuais lutam para executar tarefas de racioc√≠nio, portanto, isso requer t√©cnicas de engenharia de prompt ainda mais avan√ßadas.

Prompt:

```json
Os n√∫meros √≠mpares neste grupo somam um n√∫mero par: 15, 32, 5, 13, 82, 7, 1.
A:
```

Isso √© incorreto! Vamos tentar melhorar isso melhorando o prompt.

---

Prompt:

```json
Os n√∫meros √≠mpares neste grupo somam um n√∫mero par: 15, 32, 5, 13, 82, 7, 1.
Resolva dividindo o problema em etapas. Primeiro, identifique os n√∫meros √≠mpares, some-os e indique se o resultado √© par ou √≠mpar.
```

---

 Principais T√©cnicas

# Zero-shot & Few-shot Prompting

O conceito de zero-shot prompting refere-se √† capacidade de um modelo de linguagem de entender e executar uma tarefa sem ter recebido exemplos espec√≠ficos dessa tarefa anteriormente.

> A palavra "shot" nesse contexto se refere a "exemplo", e "prompting" seria a "cria√ß√£o de prompts".

---

# Chain-of-Thought Prompting

O conceito de Chain-of-Thought Prompting pode ser traduzido como "Cria√ß√£o de prompts com Cadeia de Pensamento".

---

Prompt

```json
P: Um paciente chega ao hospital com sintomas de febre, tosse e dificuldade para respirar. Primeiro, o meÃÅdico realiza um exame fiÃÅsico. Em seguida, solicita exames de sangue e uma radiografia do toÃÅrax. ApoÃÅs analisar os resultados, o meÃÅdico diagnostica pneumonia. Explique a sequeÃÇncia de passos que o meÃÅdico seguiu para diagnosticar a pneumonia.

R: O meÃÅdico realizou um exame fiÃÅsico para avaliar os sintomas. Depois, solicitou exames de sangue e uma radiografia do toÃÅrax para obter mais informacÃßoÃÉes. Com os resultados, diagnosticou pneumonia. A sequeÃÇncia de passos eÃÅ: exame fiÃÅsico, exames de sangue, radiografia do toÃÅrax, diagnoÃÅstico de pneumonia. (CoT aplicado)

P: Um paciente chega com dor abdominal aguda. O meÃÅdico primeiro faz um exame fiÃÅsico. Depois, pede exames de sangue e uma tomografia computadorizada. Com os resultados, identifica uma apendicite. Quais passos o meÃÅdico seguiu para diagnosticar a apendicite?
```

---

> Ele prop√µe que podemos obter respostas muito mais precisas quando demonstramos aos modelos, no pr√≥prio prompt, a forma exata de raciocinar, dando uma resposta completa como exemplo, incluindo o passo a passo para chegar a ela.

Obs. Essa t√©cnica tamb√©m √© chamada de Few-shot Chain-of-Thought Prompting (traduzindo, "Cria√ß√£o de prompts com Cadeia de Pensamento com alguns exemplos")

---

# Zero-shot Chain-of-Thought

Poucos meses depois do artigo sobre Few-shot Chain-of-Thought, uma equipe composta de cientistas da Universidade de T√≥quio, no Jap√£o, e do Google publicou outro artigo propondo que modelos de linguagem n√£o precisariam necessariamente de toda essa explica√ß√£o e exemplos (few-shot) para darem uma resposta correta.

> E que, para fazer o modelo se comportar com uma cadeia de pensamento (Chain-of-Thought), bastaria utilizar a frase "Let's think step by step" (em portugu√™s, "Vamos pensar passo a passo") no final do prompt.

---

# Self-consistency (Autoconsist√™ncia)

Essa estrat√©gia simples tamb√©m proposta pela equipe do Google consiste em usar a t√©cnica de Few-shot Chain-of-Thought para obter um conjunto de diversas respostas para um mesmo prompt e, ent√£o, escolher a resposta que apareceu o maior n√∫mero de vezes.

> Um prompt √© passado v√°rias vezes ao modelo (em janelas diferentes de chat ou em diferentes chamadas √† API, por exemplo), e diversas respostas diferentes s√£o geradas, contudo,  seleciona apenas aquela mais recorrente.

---

# Chain-of-Verification

Na Chain-of-Verification, ap√≥s o modelo gerar uma resposta inicial a um prompt, s√£o formuladas perguntas de seguimento para ajudar a verificar a veracidade e a precis√£o da resposta inicial.
Prompt

```json
Por favor, responda inicialmente de forma concisa aÃÄ minha pergunta. Em seguida, facÃßa perguntas sobre a resposta inicial e verifique os fatos apresentados nessas respostas. Exponha as perguntas e respostas do processo de verificacÃßaÃÉo detalhadamente e, com base nessa anaÃÅlise, reformule uma resposta final mais precisa e fundamentada para a minha <pergunta> (CoVE aplicado)

<pergunta> Quando o Ayrton Senna morreu? <pergunta>
```

---

# Gera√ß√£o com Recupera√ß√£o Aprimorada (RAG)

Pesquisadores de Meta IA introduziram um m√©todo chamado Gera√ß√£o com Recupera√ß√£o Aprimorada (RAG) para lidar com tarefas intensivas em conhecimento. O RAG combina um componente de recupera√ß√£o de informa√ß√µes com um modelo gerador de texto.

---

# React - Raz√£o e A√ß√£o

Yao et al., 2022 introduziu uma estrutura em que LLMs s√£o usados para gerar rastros de racioc√≠nio e a√ß√µes espec√≠ficas de tarefas de maneira intercalada. A gera√ß√£o de rastros de racioc√≠nio permite que o modelo induza, rastreie e atualize planos de a√ß√£o e at√© mesmo trate de exce√ß√µes. 

> A etapa de a√ß√£o permite interagir e coletar informa√ß√µes de fontes externas, como bases de conhecimento ou ambientes

---

 Engenharia de Prompt

Bruno Picinini e Sandeco

# T√©cnicas a serem aplicadas

---

> Definir uma Persona - identidade

```json
PROMPT: VoceÃÇ agora eÃÅ um profissional da educacÃßaÃÉo na aÃÅrea da computacÃßaÃÉo para criancÃßas e adolescentes, tem a missaÃÉo de ensinar conceitos de cieÃÇncia da computacÃßaÃÉo e habilidades de programacÃßaÃÉo de maneira acessiÃÅvel e envolvente. Sua habilidade em transformar toÃÅpicos complexos em conteuÃÅdos luÃÅdicos e praÃÅticos incentiva a criatividade e a resolucÃßaÃÉo de problemas nos jovens. Com seu conhecimento teÃÅcnico em linguagens de programacÃßaÃÉo e tecnologias emergentes, voceÃÇ estaÃÅ sempre atento aÃÄs necessidades e interesses dos alunos, criando um ambiente inclusivo e motivador que promove o pensamento criÃÅtico e a inovacÃßaÃÉo. Sua capacidade de adaptar o conteuÃÅdo para diferentes faixas etaÃÅrias e niÃÅveis de habilidade garante que todos os estudantes possam avancÃßar de forma significativa e divertida no mundo digital.
```

---

> Uso de delimitadores

```xml
PROMPT: Leia os textos delimitados por <texto1> e <texto2> e escreva um novo texto relacionando-os.

<texto1>  
Os avioÃÉes saÃÉo maÃÅquinas complexas e maravilhosas que revolucionaram o transporte e a comu- nicacÃßaÃÉo global. Capazes de percorrer grandes distaÃÇncias em curtos periÃÅodos, eles conectam pessoas, culturas e economias de maneira ineÃÅdita. Utilizando princiÃÅpios da aerodinaÃÇmica, os avioÃÉes se sustentam no ar gracÃßas aÃÄ forma de suas asas, que criam uma diferencÃßa de pressaÃÉo que permite o voo.

</texto1>  
<texto2>  
A viagem ao espacÃßo representa um dos maiores avancÃßos da humanidade, permitindo a explo-

racÃßaÃÉo de fronteiras aleÃÅm da Terra. </texto2>
```

---

> Forne√ßa Exemplos

```json
PROMPT:

Escreva um e-mail formal para um cliente sobre o atraso distribuicÃßaÃÉo de insumos. Utilize o e-mail delimitado em <exemplo> como refereÃÇncia para o tom e a estrutura.

<exemplo>  
Prezado Sr. Silva,  
GostariÃÅamos de informaÃÅ-lo sobre um atraso inesperado na entrega do seu projeto. Devido a imprevistos teÃÅcnicos, naÃÉo conseguiremos concluir o trabalho dentro do prazo inicialmente estipulado. Estamos trabalhando arduamente para resolver estas questoÃÉes e estimamos que a entrega seraÃÅ feita ateÃÅ o final da proÃÅxima semana. Pedimos desculpas pelo inconveniente e agradecemos a sua compreensaÃÉo.  
Atenciosamente,  
JoaÃÉo Pereira  
Gerente de Projetos

</exemplo>  
Agora, escreva o e-mail
```

---

Considerar os seguintes pontos em prompts mais complexos:

> Objetivo - o que espera alcan√ßar

> Modelo - formato do resultado

> Contexto - descrever o estado atual (problema)

> Refinamentos

---

> Al√©m de incluir, quando couber, controle de:

- N√≠vel de complexidade do texto: Definir escala 
- Entona√ß√£o  - definir n√≠veis
- Controle de sentimento - definir escalas
- Perpectiva - 1, 2 ou terceira pessoa.
- Controle de foco no assunto. Definir escala. Ex. Escala de Foco: 1 o foco √© amplo e 10 o foco √© muito restrito
- N√≠vel de detalhe - criar escala
- etc

---

# Processo para desenvolver PROMPTs mais completos

- Definir crit√©rios e tarefas de sucesso
  - Desempenho e precis√£o: Qu√£o bem o modelo executa o processo  
  - Lat√™ncia: tempo de resposta do modelo  
  - Pre√ßo: qual seu or√ßamento
- Desenvolver casos de teste
- Escrever o prompt ininical  
  - Processo constante de refinamento
- Teste-o contra exemplos
- Refine o prompt
- Ponha-o em produ√ß√£o

Veja o arquivo: obsidian://open?vault=TEP&file=Modelo%20de%20Agente%20com%20XML.pdf

---

 Dicas

Verificar o tamanho m√°ximo do prompt. 

> Tamanho do Prompt: 18k Caracteres (GPT)

Transformar a base de conhecimento em arquivos .json
Utilizar Recompensas e Puni√ß√µes
Estrutura√ß√£o de documentos longos. 

- Posicione antes das instru√ß√µes.

---

# Aprenda ou Revise:

- Markdown {{PDF}}
- JSON - https://quickref.me/json.html

---

 Exerc√≠cios

Para consolidar os conceitos apresentados, aqui estaÃÉo alguns exerciÃÅcios praÃÅticos para voceÃÇ aplicar as teÃÅcnicas baÃÅsicas da engenharia de prompts. 

Para cada exerc√≠cio anote o prompt inicial e a resposta obtida, o prompt final (que lhe agradou) e a resposta obtida. Segue modelo

Prompt:

```d
O C√©u √©
```

Sa√≠da:

```d
Azul
```

---

1. Crie um prompt simples pedindo ao modelo para escrever uma carta de recomendacÃßaÃÉo sem fornecer nenhum contexto adicional. Depois, revise o prompt adicionando detalhes sobre o destinataÃÅrio e o propoÃÅsito da carta. Como o contexto influenciou a qualidade da resposta?
2. Defina uma persona para um assistente virtual que auxilia clientes de uma livraria. Crie um prompt que utilize essa persona para responder clientes e indicar livros. Avalie como a definicÃßaÃÉo de persona impacta a resposta do modelo.
3. Escreva um prompt vago pedindo ao modelo para descrever um cenaÃÅrio futurista, sem dar detalhes. Depois, reescreva o prompt com instrucÃßoÃÉes claras e especiÃÅficas sobre o tipo de cenaÃÅrio e detalhes a serem incluiÃÅdos. Avalie a importaÃÇncia da clareza nas instrucÃßoÃÉes.
4. Desenvolva um prompt inicial para gerar uma breve biografia de uma figura histoÃÅrica a ser definida por voc√™. Analise a resposta e refine o prompt adicionando detalhes, informa√ß√µes adicionais e ajustando as instrucÃßoÃÉes. Realize vaÃÅrias iteracÃßoÃÉes e observe como cada refinamento melhora a precisaÃÉo da resposta.
5. Desenvolva um prompt personalizado para um posto de gasolina. Use todas as teÃÅcnicas discutidas neste capiÃÅtulo para otimizar o prompt. Avalie a eficaÃÅcia do prompt baseado na resposta do modelo e facÃßa os ajustes necessaÃÅrios. Utilize o ChatGPT ou outro servi√ßo √† sua escolha para auxiliar na gera√ß√£o de um prompt interativo.
6. Escreva dois prompts sobre o mesmo tema, mas com diferentes entonacÃßoÃÉes: um formal e outro casual. Utilize a escala de entonacÃßaÃÉo de 1 a 10.
7. Crie dois prompts para gerar textos com diferentes sentimentos sobre o mesmo assunto. Utilize a escala de sentimento de 1 a 10.
8. Crie treÃÇs prompts sobre o mesmo tema, cada um utilizando uma perspectiva diferente: primeira, segunda e terceira pessoa. Utilize a escala de perspectiva de 1 a 3.
9. Escreva dois prompts que descrevam a mesma cena, mas com diferentes niÃÅveis de detalhe. Utilize a escala de niÃÅvel de detalhe de 1 a 10.

---

 Estude as Refer√™ncias

- https://www.promptingguide.ai/

- https://learn.microsoft.com/pt-br/azure/ai-services/openai/concepts/prompt-engineering

- https://www.alura.com.br/artigos/engenharia-prompt?srsltid=AfmBOop4oY145iWN7Mu-BxxPihU-kpTdCqJmhkx7qBRk0jFt-gt0j-JP

- Cr√©dito de 200 Dolares - DigitalOcean - [DigitalOcean | Cloud Infrastructure for Developers](https://www.digitalocean.com/?refcode=fd053d06228b&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=CopyPaste)

**Ollama Course**

- https://www.youtube.com/watch?v=9KEUFe4KQAI&list=PLvsHpqLkpw0fIT-WbjY-xBRxTftjwiTLB

- **Livro do Sandeco**
- 
# Aula 5

Aula 5 -Conceitos de RAG com Langchain e Langflow
Atividades com Agentes CREW AI

Agentes de IA com CrewAI e Llama3 usando a API Groq

Este exemplo demonstra como criar agentes de IA usando a biblioteca CrewAI, o modelo Llama3 e a API Groq em Python. O objetivo √© fornecer uma estrutura b√°sica para configurar e executar agentes de IA.

Requisitos
Antes de come√ßar, certifique-se de ter os seguintes requisitos instalados:

Python 3.8 ou superior
Biblioteca CrewAI
Acesso √† API Groq para o modelo Llama3
pip para gerenciar pacotes Python
Instala√ß√£o
Clone o reposit√≥rio:

git clone https://github.com/viniciusds2020/ai_crewai_starter_template.git
cd ai_crewai_starter_template
Crie um ambiente virtual (opcional, mas recomendado):

python -m venv venv
source venv/bin/activate  # No Windows, use `venv\Scripts\activate`
Instale as depend√™ncias:

pip install -r requirements.txt
Configura√ß√£o
Obtenha uma chave de API da Groq para acessar o modelo Llama3. Registre-se no site da Groq e siga as instru√ß√µes para gerar a chave de API.

Crie um arquivo .env na raiz do projeto e adicione sua chave de API:

GROQ_API_KEY=your_api_key_here
Teste sua configura√ß√£o para verificar se est√° carregando corretamente o arquivo .env

import os
from dotenv import load_dotenv

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Verifica se a chave foi carregada corretamente
groq_api_key = os.getenv('GROQ_API_KEY')
if groq_api_key is None:
    print("A chave da API n√£o foi carregada corretamente.")
else:
    print("Chave da API carregada:", groq_api_key)
Uso
O arquivo principal main.py cont√©m a l√≥gica para inicializar e executar o agente de IA. Para iniciar o agente, execute:

python main.py
Estrutura do Projeto
.
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ .env
README.md: Este arquivo de documenta√ß√£o.
requirements.txt: Arquivo de depend√™ncias do Python.
main.py: Script principal que inicializa e executa o agente de IA.
.env: Arquivo contendo a chave de API da Groq.
Fiz alguns pequenos ajustes abaixo para facilar o uso. Revise seu arquivo.

Arquivo agents.py

### Sistemas de multi-agentes de inteligencias artificiais

# Biblioteca
from crewai_tools import tool
from crewai import Agent, Task, Crew
from langchain_groq import ChatGroq
from langchain_community.tools import DuckDuckGoSearchRun

# Modelo LLM - Llama3 
llm = ChatGroq(temperature=0.7,
               groq_api_key='sua-chave-api-groq',
               model_name='llama-3.1-8b-instant') #novo modelo

#se for usar o GPT
#llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.3)

# Ferramentas - Busca na internet com DuckDuckGo
@tool('DuckDuckGoSearchRun')
def search_tool(search_query: str):
  ''' Search the web for infotmation on a given topic'''
  return DuckDuckGoSearchRun().run(search_query)

# Topico do blog
topic = "Apple and AI in finance"

# Agentes
researcher = Agent(
    role = "Senior Researcher",
    goal = f"Explore trending technologies in {topic}.",
    backstory = "You are an innovative researher who follows the latest technology",
    verbose = True,
    tools = [search_tool],
    llm = llm,
)

writer = Agent(
    role = "Top Writer",
    goal = f"Create engaging content about {topic}. ",
    backstory = "You are an expert blogger who writes interesting articles.",
    verbose = True,
    tools = [search_tool],
    llm = llm,
)

# Tarefas
research_task = Task(
    description = f"Investigate the latest AI trends in {topic}.",
    expected_output = "A comprehensive 4 paragraphs long report on the latest AI trends.",
    tools = [search_tool],
    agent = researcher,
)

write_task = Task(
    description = f"Write an engaging article on {topic} that focuses on the latest trends.",
    expected_output = f"A comprehensive 4 paragraphs blog on {topic} in markdown format.",
    tools = [search_tool],
    agent = researcher,
    output_file = "my-blog.md"
)

# Orquestrador
crew = Crew(
    agents=[researcher, writer],
    tasks = [research_task, write_task]
)

result = crew.kickoff(
    inputs = {"topic": topic}
)
Vamos adaptar o projeto acima para pesquisar e redigir uma not√≠cia com dados recentes sobre as queimadas em Mato Grosso.

Fa√ßa uma c√≥pia do arquivo main.py para agente.py

Obs. Altere os prompts, de modo com que o resultado produzido seja em Porgu√™s do Brasil, contudo, mantenha os roles definidos para os agentes ou verifique com mais cuidado a documenta√ß√£o em crewAI Agents - crewAI.

Renomei tamb√©m o output_file = "news.md".

Ok. Quando finalizar suba tudo para seu Git OK!

Instalar o Langflow localmente
Cuidado

O Langflow  requer que  o Python vers√£o 3.10 ou superior e  o pip  ou  pipx  estejam instalados no seu sistema.

Instale o Langflow com pip:

  1  python -m pip install langflow -U           

Instale o Langflow com pipx:

  1  pipx install langflow --python python3.10 --fetch-missing-python           

O Pipx pode buscar a vers√£o Python faltante para voc√™ com  --fetch-missing-python, mas voc√™ tamb√©m pode instalar a vers√£o Python manualmente. Use  --force-reinstall para garantir que voc√™ tenha a vers√£o mais recente do Langflow e suas depend√™ncias.

‚õìÔ∏è Execute o Langflow
Para executar o Langflow, digite o seguinte comando.
  1  python -m langflow run           

Confirme se uma inst√¢ncia local do Langflow √© iniciada visitando  o site http://127.0.0.1:7860 em um navegador baseado em Chromium.


Exemplos de Fluxos no LANGFLOW
TEP - Chat com Mem√≥ria

TEP - CrewAI

TEP - PDF RAG

![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula5/Captura%20de%20tela%202024-09-12%20215701.jpg)

![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula5/datastax.jpg)

[Ver o arquivo git.txt](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula5/git.txt)

[Ver o arquivo Chat com Mem√≥ria.json](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula5/Chat%20com%20memoria.json)

# Aula 6
Chatbots com base de conhecimento - Dify

![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/1.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/2.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/3.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/4.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/5.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/6.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/7.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/8.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/9.jpg)

[Ver o arquivo RAG documents.json](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/RAG%20documents.json)

[Ver o arquivo DataStax.json](https://github.com/ViniciusLGreco/AulasTEP/blob/main/Aula6/datastax%20aula%2006.json)

# Aula 7
**Docker**
Docker √© uma plataforma open source que possibilita o empacotamento de uma aplica√ß√£o dentro de um container. Uma aplica√ß√£o consegue se adequar e rodar em qualquer m√°quina que tenha essa tecnologia instalada.

Porque usar WSL 2 + Docker para desenvolvimento
Configurar ambientes de desenvolvimento no Windows sempre foi burocr√°tico e complexo, al√©m do desempenho de algumas ferramentas n√£o serem totalmente satisfat√≥rias.

Com o nascimento do Docker este cen√°rio melhorou bastante, pois podemos montar nosso ambiente de desenvolvimento baseado em Unix, de forma independente e r√°pida, e ainda unificada com outros sistemas operacionais.

Modos de usar Docker no Windows
Docker Desktop com WSL2
Roda em cima do Virtual Machine Platform que √© um componente do Hyper-V e se integra com o WSL2 permitindo rodar o Docker dentro do ambiente do Linux.

N√£o √© necess√°rio adquirir licen√ßa PRO do Windows 10/11.

Tem um grande desempenho e consome menos recursos quando comparado ao Docker Toolbox ou Docker Desktop com Hyper-V.

Algumas Vantagens
Tem uma ferramenta visual para administrar o Docker.
Permite instalar extens√µes para usar ferramentas diretas no Docker.
Permite rodar um cluster Kubernetes localmente de forma f√°cil.
Simplifica a configura√ß√£o do Docker tanto no Windows quanto no WSL 2.
Algumas Desvantagens
Uso de mem√≥ria inicial sem rodar nenhum container Docker √© de 1GB ou mais.
Pode ser necess√°rio reiniciar o Docker Desktop para que ele funcione corretamente em algumas situa√ß√µes.
Tende a consumir mais recursos da m√°quina que o Docker Engine diretamente instalado no WSL 2.
Docker Engine (Docker Nativo) diretamente instalado no WSL2
O Docker Engine √© o Docker nativo (como foi criado) que roda no ambiente Linux e completamente suportado para WSL 2. Sua instala√ß√£o √© id√™ntica a descrita para as pr√≥prias distribui√ß√µes Linux disponibilizadas no site do Docker.

√â a maneira pura de usar o Docker no Linux.

Algumas Vantagens
Consume menos mem√≥ria para rodar o Docker Daemon (servidor do Docker) quando comparado ao Docker Desktop.

Traz a experi√™ncia mais pura de usar o Docker no Linux.

Algumas Desvantagens
Se necessitar executar o Docker em outra inst√¢ncia do WSL 2, √© necess√°rio instalar novamente o Docker nesta inst√¢ncia ou configurar o acesso ao socket do Docker desejado para compartilhar o Docker entre as inst√¢ncias.

**2 - Instalar o Docker com Docker Engine (Docker Nativo)**
A instala√ß√£o do Docker no WSL 2 √© id√™ntica a instala√ß√£o do Docker em sua pr√≥pria distribui√ß√£o Linux, portanto se voc√™ tem o Ubuntu √© igual ao Ubuntu, se √© Fedora √© igual ao Fedora. A documenta√ß√£o de instala√ß√£o do Docker no Linux por distribui√ß√£o est√° aqui, mas vamos ver como instalar no Ubuntu.

![[Pasted image 20240822100956.png]]

O que o WSL 2 pode usar de recursos da sua m√°quina
Podemos dizer que o WSL 2 tem acesso quase que total ao recursos de sua m√°quina. Ele tem acesso por padr√£o:

A 1TB de disco r√≠gido. √â criado um disco virtual de 1TB para armazenar os arquivos do Linux (este limite pode ser expandido, ver a √°rea de dicas e truques).
A usar completamente os recursos de processamento.
A usar 50% da mem√≥ria RAM dispon√≠vel.
A usar 25% da mem√≥ria dispon√≠vel para SWAP (mem√≥ria virtual).
Se voc√™ quiser personalizar estes limites, crie um arquivo chamado .wslconfig na raiz da sua pasta de usu√°rio (C:\Users\<seu_usuario>) e defina estas configura√ß√µes:

[wsl2]
memory=8GB
processors=4
Instalando Docker
https://docs.docker.com/engine/install/ubuntu/

Install using the apt repository
Before you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.

Set up Docker's apt repository.

# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
Install the Docker packages.

Latest Specific version
To install the latest version, run:

$ sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
Verify that the Docker Engine installation is successful by running the hello-world image.

$ sudo docker run hello-world
Fazer Ate aqui

https://github.com/codeedu/wsl2-docker-quickstart
https://learn.microsoft.com/pt-br/windows/terminal/install

**Passo 3: Inicialize os recursos do Docker**
Agora que voc√™ tem uma aplica√ß√£o, podemos iniciar o processo de containeriza√ß√£o. Dentro do diret√≥rio 'docker-nodejs-sample', execute o comando 'docker init' em um terminal e siga as instru√ß√µes:

Crie um Dockerfile
Crie um arquivo chamado Dockerfile na pasta principal do seu projeto. Este arquivo ir√° conter as instru√ß√µes para construir a imagem Docker do seu projeto.

# Use uma imagem base oficial do Node.js
FROM node:14

# Defina o diret√≥rio de trabalho dentro do container
WORKDIR /usr/src/app

# Copie o arquivo package.json e package-lock.json (se existir)
COPY package*.json ./

# Instale as depend√™ncias do projeto
RUN npm install

# Copie o restante do c√≥digo do projeto
COPY . .

# Exponha a porta que o aplicativo Node.js estar√° escutando
EXPOSE 3000

# Comando para rodar o aplicativo
CMD ["node", "src/index.js"]
Crie um arquivo .dockerignore
node_modules
npm-debug.log
Dockerfile
.dockerignore
Construa a Imagem Docker
No terminal, navegue at√© a pasta principal do seu projeto e execute o seguinte comando para construir a imagem Docker:

docker images
docker build -t meu-app-node .
Execute o Container:
Ap√≥s a constru√ß√£o da imagem, voc√™ pode executar um container a partir dela com o seguinte comando:

docker images
docker run -p 3000:3000 meu-app
docker run -p 3000:3000 -d meu-app
docker ps
docker stop
docker rm CONTAINERID
docker rmi -f meu-app
Isso mapear√° a porta 3000 do container para a porta 3000 do seu host, permitindo que voc√™ acesse o aplicativo Node.js em http://localhost:3000

Utilizando o Docker compose
Utilizar o Docker Compose √© uma √≥tima maneira de gerenciar m√∫ltiplos containers Docker de forma orquestrada, especialmente √∫til para aplicativos que dependem de v√°rios servi√ßos, como bancos de dados, servidores de cache, etc. Aqui est√£o os passos para configurar e usar o Docker Compose com seu projeto Node.js:

Certifique-se de que o Docker Compose est√° instalado no seu sistema. Voc√™ pode verificar isso com o comando:

docker compose version
Crie um arquivo docker-compose.yml:

version: '3'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    volumes:
      - .:/usr/src/app
    environment:
      - NODE_ENV=production
Construa e Execute os Servi√ßos:
No terminal, navegue at√© a pasta principal do seu projeto e execute o seguinte comando para construir e iniciar os servi√ßos definidos no docker-compose.yml:

docker compose up --build
Verifique os Servi√ßos:

docker compose ps
#parar servi√ßo
docker compose down
Use docker-compose up -d quando quiser iniciar os servi√ßos usando as imagens j√° constru√≠das, sem reconstruir as imagens.

Use docker-compose up --build -d quando quiser garantir que as imagens sejam reconstru√≠das antes de iniciar os servi√ßos, o que √© √∫til ap√≥s fazer altera√ß√µes no c√≥digo-fonte ou no Dockerfile.

Exemplo de um arquivo com dois servi√ßos
version: '3'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    volumes:
      - .:/usr/src/app
    environment:
      - NODE_ENV=production

  db:
    image: mysql:8
    ports:
      - "3306:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=mysecretpassword
      - MYSQL_DATABASE=mydatabase
      - MYSQL_USER=myuser
      - MYSQL_PASSWORD=mypassword
As vari√°veis de ambiente correspondem √†s necessidades do MySQL:

MYSQL_ROOT_PASSWORD: Define a senha do usu√°rio root.

MYSQL_DATABASE: Define o nome do banco de dados que ser√° criado.

MYSQL_USER: Define o nome de um usu√°rio n√£o-root que ser√° criado.

MYSQL_PASSWORD: Define a senha para o usu√°rio n√£o-root.

Refer√™ncia:
https://blog.rocketseat.com.br/containerizando-uma-aplicacao-node-js-com-docker-um-guia-passo-a-passo/

![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula7/1.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula7/2.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula7/3.jpg)
![Print da aula](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula7/4.jpg)

[Ver o arquivo RAG documents.json](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula7/RAG%20Documentos.json)

[Ver o arquivo CrewAI.json](https://github.com/ViniciusLGreco/AulasTEP/blob/main/aula7/TEP_-_CrewAI.json)


# Aula 8
## FLuxo - Revenda

### Formato de Resposta do Modelo - Json Schema

```json
{
  "name": "carro_escolha",
  "schema": {
    "type": "object",
    "properties": {
      "nome": {
        "type": "string",
        "description": "o nome da pessoa"
      },
      "carro": {
        "type": "string",
        "description": "o carro que o usu√°rio escolheu, se n√£o souber marque \"\""
      },
      "response": {
        "type": "string",
        "description": "Sua resposta para o usu√°rio"
      },
      "etapa": {
        "type": "integer",
        "description": "o n√∫mero da etapa em que voc√™ se encontra com descrito nas tags"
      }
    }
  }
}
```

Prompt LLM 1

```xml
<contexto>
Seu nome √© Clara, voc√™ trabalha na Concecionaria Auto Carros.
No inicio da conversa, envie sempre a logo da loja, no formato markdown:

!["Auto Carros"](https://www.veiculoaqui.com.br/fotos_lojas/loja20231122131932721_535130177.jpeg)


Voc√™ deve orientar o usu√°rio a encontrar o carro ideal.
</contexto>

<etapas>
1. Solicite o nome do usu√°rio
2. Pergunte para que tipo de uso ser√° o carro
3. Fa√ßa poucas perguntas para identificar o carro ideal para o cliente
4. Sugira um carro ou uma lista de carros com base no perfil dele
5. Assim que o usu√°rio escolher o carro, agrade√ßa e diga que ir√° encaminh√°-lo para o Gerente Caetano, que ir√° agendar um teste Drive.
</etapas> 

<response_format>
Responda no formato JSON com os seguintes campos:
response - Sua resposta para o usu√°rio
carro - o carro que o usu√°rio escolheu, se n√£o souber marque ""
nome - o nome do usu√°rio, se n√£o souber, marque ""
etapa - o n√∫mero da etapa em que voc√™ se encontra com descrito nas tags <etapas>

</response_format>
```

Prompt LLM 2

```xml
<contexto>
Seu nome √© Caetano e voc√™ √© respons√°vel por agendar o teste drive com o cliente em nossa concession√°ria.
</contexto>

<etapas>
1. Pergunte o endere√ßo do usu√°rio
2. Sugira os pr√≥ximos dois dias para agendamento, hoje √© {{ data_atual }}, {{ dia_da_semana }}.
3. Sugira dois hor√°rios, um de manh√£ e outro de tarde.
4. Agrade√ßa ao usu√°rio e diga que ir√° aguard√°-lo.

</etapas>
```

C√≥digo: Pegar a data atual

```python
from datetime import datetime
def main() -> dict:
    # Dicion√°rio para mapear os dias da semana em portugu√™s
    days_of_week = {
        0: "Segunda-feira",
        1: "Ter√ßa-feira",
        2: "Quarta-feira",
        3: "Quinta-feira",
        4: "Sexta-feira",
        5: "S√°bado",
        6: "Domingo"
    }

    # Obt√©m a data atual
    current_date = datetime.now()

    # Formata a data no formato dd/mm/aaaa
    formatted_date = current_date.strftime("%d/%m/%Y")

    # Obt√©m o dia da semana em portugu√™s
    day_of_week = days_of_week[current_date.weekday()]

    # Retorna a data e o dia da semana
    return {
        "data_atual": formatted_date,
        "dia_da_semana": day_of_week
    }
```

2024-10-11T08:00:00.000Z

2024-10-14T08:00:00.000Z

2024-10-14T09:00:00.000Z

2024-10-14T10:00:00.000Z

# Aula 9


Implementa√ß√£o de chatbot/Agent no Dify
Uso de ferramentas para acessar a API do Cal.com

```xml
<Agent>
  <contexto>
  Na Cl√≠nica M√©dica Sa√∫de Total, oferecemos servi√ßos completos de fisioterapia voltados √† recupera√ß√£o e ao bem-estar dos nossos pacientes. O Dr. Benevid Felix da Silva, especialista na √°rea, est√° √† disposi√ß√£o para proporcionar tratamentos personalizados, incluindo:

Reabilita√ß√£o Muscular e Articular: Tratamentos para al√≠vio de dores e recupera√ß√£o de movimentos em les√µes, p√≥s-operat√≥rios e condi√ß√µes cr√¥nicas.
Terapias Preventivas: Fisioterapia preventiva para fortalecer m√∫sculos, melhorar a postura e evitar futuras les√µes.
Tratamento de Condi√ß√µes Neuromusculares: Reabilita√ß√£o focada em pacientes com doen√ßas neurol√≥gicas, como AVC, esclerose m√∫ltipla e Parkinson.
Fisioterapia Ortop√©dica: Cuidados especializados para recupera√ß√£o de fraturas, tor√ß√µes e problemas ortop√©dicos.
Nosso objetivo √© melhorar a qualidade de vida dos pacientes por meio de tratamentos eficazes e personalizados.
  </contexto>
  
  
  
    <Description>
        O agente virtual da Cl√≠nica M√©dica Sa√∫de Total √© projetado para ajudar pacientes com agendamentos de consultas, fornecimento de informa√ß√µes sobre servi√ßos m√©dicos, esclarecimento de d√∫vidas e gerenciamento de registros de pacientes.
    </Description>

    <Language>pt-BR</Language>

<Hour>
Utilize como padr√£o o fuso hor√°rio GMT -4, descontando e atualizando a hora fornecida pela ferramenta current_time, que est√° em GMT 0.  N√£o d√™ informa√ß√µes sobre o fuso, apenas informe horas. 
</Hour>

<weekday>
Utilize o GMT -4 para informar o dia da semana, considerando que a ferramenta current_time est√° em GMT 0. Fa√ßa os c√°lculos de horas a menos para informar o dia correto.
</weekday>
 
<CommunicationStyle>
        <Tone>Calmo e acolhedor</Tone>
        <Formality>Formal</Formality>
</CommunicationStyle>
    
<etapas>
1. Solicite o nome da pessoa, email e telefone. Esses dados s√£o necess√°rios para fazer o agendamento da consulta.
2. Pergunte para que dia deseja agendar a consulta.
3. Fa√ßa poucas perguntas para identificar os dados junto ao cliente
4. Sugira uma data com base na lista de slots vagos. Os slots vagos para agendamento podem ser consultados utilizando a ferramenta get_slots_cal_com.
5. Assim que o usu√°rio escolher o hor√°rio, fa√ßa o agendamento utilizando a ferramenta criar_agendamento_cal_com. Confirme o agendamento com a ferramenta get_bookings_cal_com.
6.Ao confirmar o agendamento
</etapas> 


</Agent>
```


## Defini√ß√£o dos temas dos trabalhos

üöÄ Proposta de Tema para Trabalho de T√≥picos Especiais em Programa√ß√£o üöÄ

## üìù Informa√ß√µes B√°sicas

- **Nome do Aluno(s):** [Nome do Aluno 1], [Nome do Aluno 2], ...

## üéØ Tema Proposto

### üìå T√≠tulo do Projeto

[Insira o t√≠tulo do projeto aqui]

### üìå Descri√ß√£o do Projeto

[Descreva o tema proposto de forma clara e concisa. Explique o problema que o projeto visa resolver e qual √© a sua relev√¢ncia para o mercado ou para a sociedade.]

### üìå Objetivos

[Liste os objetivos principais do projeto. Por exemplo, automatizar um processo espec√≠fico, melhorar a efici√™ncia de um sistema, etc.]

### üìå Ferramentas e Tecnologias Sugeridas

[Liste as ferramentas e tecnologias que voc√™s planejam utilizar para desenvolver o projeto. Exemplos: LLM, RAG, Langchain, Dify, N8N, etc.]

### üìå Funcionalidades Principais

[Descreva as principais funcionalidades que o sistema ou aplicativo ter√°. Use uma lista para facilitar a visualiza√ß√£o.]

- Funcionalidade 1: [Descri√ß√£o da funcionalidade 1]
- Funcionalidade 2: [Descri√ß√£o da funcionalidade 2]
- Funcionalidade 3: [Descri√ß√£o da funcionalidade 3]
- ...

### üìå Atividades por Membro da Equipe

[Especifique as atividades que cada membro da equipe ir√° desenvolver. Isso ajuda a garantir que todas as partes do projeto sejam cobertas.]

- **[Nome do Aluno 1]:** [Atividade 1], [Atividade 2], ...
- **[Nome do Aluno 2]:** [Atividade 1], [Atividade 2], ...
- ...

### üìå Cronograma Preliminar

[Proponha um cronograma preliminar para o desenvolvimento do projeto. Use uma tabela para listar as principais etapas e prazos.]

| Etapa | Descri√ß√£o              | Prazo  | Respons√°vel(eis)   |
| ----- | ---------------------- | ------ | ------------------ |
| 1     | [Descri√ß√£o da Etapa 1] | [Data] | [Nome do Aluno(s)] |
| 2     | [Descri√ß√£o da Etapa 2] | [Data] | [Nome do Aluno(s)] |
| ...   | ...                    | ...    | ...                |

### üìå Refer√™ncias

[Liste as principais refer√™ncias que voc√™s utilizar√£o para desenvolver o projeto. Isso pode incluir artigos, documenta√ß√µes de APIs, tutoriais, etc.]

- Refer√™ncia 1: [Descri√ß√£o da Refer√™ncia 1]
- Refer√™ncia 2: [Descri√ß√£o da Refer√™ncia 2]
- ...

## üì¨ Envio da Proposta

Enviar atrav√©s do SIGAA, na Tarefa correspondente. Caso tenha d√∫vidas, encaminhe via whatsapp professor antes de submeter a tarefa.

---

**Observa√ß√£o:** Certifique-se de que a proposta esteja clara, detalhada e coerente com os objetivos do trabalho de T√≥picos Especiais em Programa√ß√£o. A equipe avaliar√° a viabilidade e a relev√¢ncia do tema proposto.

# Aula 10

Instala√ß√£o do N8n


## APIS do WhatsApp
### go-whatsapp-web-multidevice

- Send WhatsApp message via http API,¬†
- [docs/openapi.yml](https://github.com/aldinokemal/go-whatsapp-web-multidevice/blob/main/docs/openapi.yaml)¬†for more details
- Compress image before send
- Compress video before send

Arquivo: docker-compose.yaml

```bash
version: '3.9'
services:
  whatsapp_go:
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"
    image: "aldinokemal2104/go-whatsapp-web-multidevice:latest"
    build:
      context: .
      dockerfile: ./docker/golang.Dockerfile
    restart: 'always'
    ports:
      - "3100:3000"
    environment:
      - WEBHOOK="https://n8n.semcodigo.edu.pl/webhook-test/consultavendas"
    volumes:
      - whatsapp_data:/app/storages

volumes:
  whatsapp_data:
```




```bash
sudo docker run --detach --publish=3001:3000 --name=whatsapp2 --restart=always --volume=$(sudo docker volume create --name=whatsapp2):/app/storages aldinokemal2104/go-whatsapp-web-multidevice --autoreply="Don't reply this message please" --webhook="http://localhost:5678/webhook-test/whats"
```


### Evolution


A Evolution API v2 est√° pronta para o Docker e pode ser facilmente implantada com Docker no modo standalone ou swarm. O reposit√≥rio oficial do Evolution API cont√©m todos os arquivos de composi√ß√£o necess√°rios para instalar e executar a API.

Originalmente, a¬†**Evolution API**¬†come√ßou como uma API de controle de WhatsApp baseada no CodeChat, utilizando a biblioteca Baileys. Com o tempo, a plataforma se expandiu para suportar n√£o apenas o WhatsApp, mas tamb√©m integra√ß√µes com servi√ßos como¬†**Typebot, Chatwoot, Dify e OpenAI**. Al√©m disso, a Evolution API suporta tanto a API de WhatsApp baseada no Baileys quanto a API oficial do WhatsApp Business, com suporte futuro planejado para Instagram e Messenger.

Processo de Instala√ß√£o: 
- https://doc.evolution-api.com/v2/pt/install/docker


O banco de dados √© uma parte fundamental da Evolution API v2, respons√°vel por armazenar todas as informa√ß√µes cr√≠ticas da aplica√ß√£o. A API suporta tanto PostgreSQL quanto MySQL, utilizando o Prisma como ORM (Object-Relational Mapping) para facilitar a intera√ß√£o com esses bancos de dados.

A maneira mais f√°cil e r√°pida de configurar um banco de dados para a Evolution API v2 √© atrav√©s do Docker. Abaixo est√£o as instru√ß√µes para configurar tanto o PostgreSQL quanto o MySQL usando Docker Compose.

##### Instala√ß√£o do Postgres

Para configurar o PostgreSQL via Docker, siga os passos abaixo:

1. Baixe o arquivo¬†`docker-compose.yaml`¬†para o PostgreSQL dispon√≠vel¬†[aqui](https://github.com/EvolutionAPI/evolution-api/blob/v2.0.0/Docker/postgres/docker-compose.yaml).

```bash
version: '3.3'

services:
  postgres:
    container_name: postgres
    image: postgres:15
    networks:
      - evolution-net
    command: ["postgres", "-c", "max_connections=1000"]
    restart: always
    ports:
      - 5432:5432
    environment:
      - POSTGRES_PASSWORD=PASSWORD
    volumes:
      - postgres_data:/var/lib/postgresql/data
    expose:
      - 5432

  pgadmin:
    image: dpage/pgadmin4:latest
    networks:
      - evolution-net
    environment:
      - PGADMIN_DEFAULT_EMAIL=EMAIL
      - PGADMIN_DEFAULT_PASSWORD=PASSWORD  
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    ports:
      - 4000:80
    links:
      - postgres

volumes:
  postgres_data:
  pgadmin_data:


networks:
  evolution-net:
    name: evolution-net
    driver: bridge
```


No meu caso, com base nas listas de redes dispon√≠veis no docker - j√° com outras ferramentas instanciadas, como n8n, Dify e Langflow tive que **alterar a porta e tamb√©m a subrede**.

```bash
version: '3.3'

services:
postgres:
    container_name: postgres
    image: postgres:15
    networks:
      - evolution-net
    command: ["postgres", "-c", "max_connections=1000"]
    restart: always
    ports:
      - 5433:5432  # Mapeia a porta 5433 no host para a porta 5432 no cont√™iner
    environment:
      - POSTGRES_PASSWORD=8H4a10032024
    volumes:
      - postgres_data:/var/lib/postgresql/data
    expose:
      - 5432  # Mant√©m a porta 5432 para exposi√ß√£o interna

  pgadmin:
    image: dpage/pgadmin4:latest
    networks:
      - evolution-net
    environment:
      - PGADMIN_DEFAULT_EMAIL=benevid@unemat.br
      - PGADMIN_DEFAULT_PASSWORD=8H4a10032024  
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    ports:
      - 4000:80
    links:
      - postgres

volumes:
  postgres_data:
  pgadmin_data:


networks:
  evolution-net:
    name: evolution-net
    driver: bridge
    ipam:
      config:
        - subnet: 172.22.0.0/16
```

No meu caso tive que rodar o seguinte comando para criar o banco de dados:

```bash
docker-compose up -d
docker exec -it postgres psql -U postgres -c "CREATE DATABASE evolution;"
```

Vari√°veis de ambiente para habilitar no `.env`

```bash
# Habilitar o uso do banco de dados
DATABASE_ENABLED=true

# Escolher o provedor do banco de dados: postgresql ou mysql
DATABASE_PROVIDER=postgresql

# URI de conex√£o com o banco de dados
DATABASE_CONNECTION_URI='postgresql://user:pass@localhost:5432/evolution?schema=public'

# Nome do cliente para a conex√£o do banco de dados
DATABASE_CONNECTION_CLIENT_NAME=evolution_exchange

# Escolha os dados que voc√™ deseja salvar no banco de dados da aplica√ß√£o
DATABASE_SAVE_DATA_INSTANCE=true
DATABASE_SAVE_DATA_NEW_MESSAGE=true
DATABASE_SAVE_MESSAGE_UPDATE=true
DATABASE_SAVE_DATA_CONTACTS=true
DATABASE_SAVE_DATA_CHATS=true
DATABASE_SAVE_DATA_LABELS=true
DATABASE_SAVE_DATA_HISTORIC=true

```


### Instala√ß√£o do Redis
O Redis √© utilizado pela Evolution API v2 como um sistema de cache para otimizar o desempenho e a velocidade da aplica√ß√£o. Ele pode ser configurado para armazenar informa√ß√µes tempor√°rias e melhorar a efici√™ncia das opera√ß√µes.

Para configurar o Redis via Docker, siga os passos abaixo:

1. Baixe o arquivo¬†`docker-compose.yaml`¬†para o Redis dispon√≠vel¬†[aqui](https://github.com/EvolutionAPI/evolution-api/blob/v2.0.0/Docker/redis/docker-compose.yaml).
2. Navegue at√© o diret√≥rio onde o arquivo foi baixado e execute o comando:

```bash
docker-compose up -d
```

```bash
version: '3.3'

services:
  redis:
    image: redis:latest
    container_name: redis
    command: >
      redis-server --port 6379 --appendonly yes
    volumes:
      - evolution_redis:/data
    ports:
      - 6380:6379

volumes:
  evolution_redis:

networks:
  evolution-net:
    name: evolution-net
    driver: bridge
```


Vari√°veis de ambiente para habilitar no `.env`

```bash
# Habilitar o cache Redis
CACHE_REDIS_ENABLED=true

# URI de conex√£o com o Redis
CACHE_REDIS_URI=redis://localhost:6379/6

# Prefixo para diferenciar os dados de diferentes instala√ß√µes que utilizam o mesmo Redis
CACHE_REDIS_PREFIX_KEY=evolution

# Habilitar para salvar as informa√ß√µes de conex√£o no Redis ao inv√©s do banco de dados
CACHE_REDIS_SAVE_INSTANCES=false

# Habilitar o cache local
CACHE_LOCAL_ENABLED=false
```


**Instala√ß√£o da Evolution**


```bash
version: '3.9'
services:
  evolution-api:
    container_name: evolution_api
    image: atendai/evolution-api:v2.1.1
    restart: always
    ports:
      - "8080:8080"
    env_file:
      - .env
    volumes:
      - evolution_instances:/evolution/instances

volumes:
  evolution_instances:

```

No meu tive que mudar a porta de sa√≠da porque dava choque com outra ferramenta. Ficando assim:

```bash
version: '3.9'
services:
  evolution-api:
    container_name: evolution_api
    image: atendai/evolution-api:v2.0.9-rc
    restart: always
    ports:
      - "8081:8080" # Mapeia 8081 (host) p/ 8080 (cont√™iner)
    env_file:
      - .env
    volumes:
      - evolution_instances:/evolution/instances

volumes:
  evolution_instances:
```

Em seguida, crie um arquivo¬†`.env`¬†no mesmo diret√≥rio com o seguinte conte√∫do m√≠nimo:

```bash
AUTHENTICATION_API_KEY=mude-me
```


Arquivo final do `.env`

```bash
## ------------------- BANCO DE DADOS -----------------------
# Habilitar o uso do banco de dados
DATABASE_ENABLED=true

# Escolher o provedor do banco de dados: postgresql ou mysql
DATABASE_PROVIDER=postgresql

# URI de conex√£o com o banco de dados
DATABASE_CONNECTION_URI='postgresql://postgres:8H4a10032024@5.78.105.1:5433/evolution?schema=public'
# Nome do cliente para a conex√£o do banco de dados
DATABASE_CONNECTION_CLIENT_NAME=evolution_exchange

# Escolha os dados que voc√™ deseja salvar no banco de dados da aplica√ß√£o
DATABASE_SAVE_DATA_INSTANCE=true
DATABASE_SAVE_DATA_NEW_MESSAGE=true
DATABASE_SAVE_MESSAGE_UPDATE=true
DATABASE_SAVE_DATA_CONTACTS=true
DATABASE_SAVE_DATA_CHATS=true
DATABASE_SAVE_DATA_LABELS=true
DATABASE_SAVE_DATA_HISTORIC=true

## ----------------------- REDIS -------------------

# Habilitar o cache Redis
CACHE_REDIS_ENABLED=true

# URI de conex√£o com o Redis
CACHE_REDIS_URI=redis://5.78.105.1:6380/6

# Prefixo para diferenciar os dados de diferentes instala√ß√µes que utilizam o mesmo Redis
CACHE_REDIS_PREFIX_KEY=evolution

# Habilitar para salvar as informa√ß√µes de conex√£o no Redis ao inv√©s do banco de dados
CACHE_REDIS_SAVE_INSTANCES=false

# Habilitar o cache local
CACHE_LOCAL_ENABLED=false

AUTHENTICATION_API_KEY=bccb5913-0ba2-41e9-b67c-05dca0be1791
```


Iniciar o evolution

```bash
docker compose up -d
docker logs evolution_api
```



```json
{ "slots": { "2024-10-28": [ { "time": "2024-10-28T12:00:00.000Z" }, { "time": "2024-10-28T13:00:00.000Z" }, { "time": "2024-10-28T14:00:00.000Z" }, { "time": "2024-10-28T15:00:00.000Z" }, { "time": "2024-10-28T16:00:00.000Z" }, { "time": "2024-10-28T17:00:00.000Z" }, { "time": "2024-10-28T18:00:00.000Z" }, { "time": "2024-10-28T19:00:00.000Z" }, { "time": "2024-10-28T20:00:00.000Z" } ], "2024-10-29": [ { "time": "2024-10-29T17:00:00.000Z" }, { "time": "2024-10-29T18:00:00.000Z" }, { "time": "2024-10-29T19:00:00.000Z" }, { "time": "2024-10-29T20:00:00.000Z" } ], "2024-10-30": [ { "time": "2024-10-30T12:00:00.000Z" }, { "time": "2024-10-30T13:00:00.000Z" }, { "time": "2024-10-30T14:00:00.000Z" }, { "time": "2024-10-30T15:00:00.000Z" }, { "time": "2024-10-30T16:00:00.000Z" }, { "time": "2024-10-30T17:00:00.000Z" }, { "time": "2024-10-30T18:00:00.000Z" }, { "time": "2024-10-30T19:00:00.000Z" }, { "time": "2024-10-30T20:00:00.000Z" } ] } }
```

